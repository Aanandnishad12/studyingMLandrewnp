{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def compute_gradient(w,b,x_train,y_train):\n",
    "    for i in range(len(x_train)):\n",
    "        f_w = w*x_train[i] + b\n",
    "        new = f_w-y_train[i]\n",
    "        new = new*x_train[i]\n",
    "        f_b = w*x_train[i] + b\n",
    "        new1 = f_b-y_train[i]\n",
    "    return new/len(x_train), new1/len(x_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cost_fintion(w,b,x_train,y_train):\n",
    "    for i in range(len(x_train)):\n",
    "\n",
    "        f_wb = w*x_train[i] + b\n",
    "        f_wd = f_wb-y_train[i]\n",
    "        fw = f_wd**2\n",
    "    return fw/len(x_train)\n",
    "\n",
    "\n",
    "iteration = 10000\n",
    "x_train = np.array([1.0, 2.0])   #features\n",
    "y_train = np.array([300.0, 500.0]) \n",
    "alpha = 0.01\n",
    "w = 0\n",
    "b = 0\n",
    "\n",
    "for i in range(iteration):\n",
    "    f_w,f_b = compute_gradient(w,b,x_train,y_train)\n",
    "    print(cost_fintion(w,b,x_train,y_train))\n",
    "    w = w-alpha*f_w\n",
    "    b = b-alpha*f_b\n",
    "\n",
    "print(w*1+b)\n",
    "print(w*2+b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implemetation of linear regression multiveribale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def f_x(w,b,x):\n",
    "    delta_w = 0\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(x[i])):\n",
    "            delta_w += x[i][j]*w[j]\n",
    "    delta_w+=b\n",
    "    return  delta_w\n",
    "\n",
    "\n",
    "def compute_gredient(w,b,X_train,y_train,):\n",
    "    dj_dw = np.zeros((X_train.shape[1],))\n",
    "    dj_db= 0\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        delta = f_x(w,b,X_train)\n",
    "        delta = delta - y_train[i]\n",
    "        print(delta)\n",
    "\n",
    "        for j in range(len(X_train[1])):\n",
    "            dj_dw[j] = dj_dw[j] + delta*X_train[i,j]\n",
    "        dj_db = dj_db +delta\n",
    "    # print(dj_dw)\n",
    "    return dj_dw/len(X_train), dj_db/len(X_train)\n",
    "\n",
    "\n",
    "iterrations = 1000\n",
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n",
    "w = np.zeros((X_train.shape[1],))\n",
    "print(w)\n",
    "alpha = 0.001\n",
    "b = 0\n",
    "for i in range(iterrations):\n",
    "    # print(w)\n",
    "    dj_dw,dj_db = compute_gredient(w,b,X_train,y_train)\n",
    "    w = w-alpha*dj_dw\n",
    "    b = b- alpha*dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "new = ['size(sqft)','bedrooms','floors','age',\"price\"]\n",
    "df = pd.read_csv(\"houses.txt\",names=new)\n",
    "X_train = df.iloc[:,:4]\n",
    "y = df.iloc[:,4]\n",
    "# print(X_train)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size,ax = plt.subplots(1,4,figsize =(12,3),sharey=True)\n",
    "# print(size)\n",
    "# print(ax)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(X_train.iloc[:,i],y)\n",
    "    ax[i].set_xlabel(new[i])\n",
    "\n",
    "# ax[i+1].scatter(X_train.iloc[:,i+1],y)\n",
    "ax[0].set_ylabel(new[-1])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def compute_gradient(X, y, w, b): \n",
    "\n",
    "    m,n = X.shape           \n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw\n",
    "\n",
    "\n",
    "\n",
    "initial_w = np.array([0,0,0,0])\n",
    "initial_b = 0.\n",
    "num_iters = 1000\n",
    "alpha = 5.0e-7\n",
    "\n",
    "w = copy.deepcopy(initial_w)  \n",
    "b = initial_b\n",
    "X = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y = np.array([460, 232, 178])\n",
    "for i in range(num_iters):\n",
    "\n",
    "    dj_db,dj_dw = compute_gradient(X, y, w, b)   \n",
    "\n",
    "    w = w - alpha * dj_dw               \n",
    "    b = b - alpha * dj_db               \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def compute_gradient(X, y, w, b): \n",
    "\n",
    "    m,n = X.shape           \n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw\n",
    "\n",
    "\n",
    "initial_w = np.array([0,0,0,0])\n",
    "initial_b = 0.\n",
    "num_iters = 1000\n",
    "alpha = 5.0e-7\n",
    "\n",
    "\n",
    "# loading the data part \n",
    "new = ['size(sqft)','bedrooms','floors','age',\"price\"]\n",
    "df = pd.read_csv(\"houses.txt\",names=new)\n",
    "X_train = df.iloc[:,:4]\n",
    "y = df.iloc[:,4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax = plt.subplots(1,4,figsize=(10,3),sharey=True)\n",
    "# plt.show()\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(df.iloc[:,i],y)\n",
    "    ax[i].set_xlabel(new[i])\n",
    "# ax[0].scatter(df.iloc[:,-1])\n",
    "ax[0].set_ylabel(str(new[-1])+ \"in (1000's)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax=plt.subplots(1, 4, figsize=(12, 3), sharey=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = df.iloc[:,:4]\n",
    "# print(X_train)\n",
    "l = []\n",
    "for i in range(len(X_train)):\n",
    "    l.append(X_train.iloc[i,:].values)\n",
    "\n",
    "new_X_train = np.array(l)\n",
    "new_y_train = y.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_X_train\n",
    "# new_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n",
    "\n",
    "\n",
    "m,n = X_train.shape\n",
    "print(m,n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grdient(w,b,x,y):\n",
    "    var = compute_cost(w,b,x,y)\n",
    "    dj_dw = np.array([0,0,0,0])\n",
    "    dj_db = 0\n",
    "    for i in range(m):\n",
    "        err = (np.dot(x[i],w)+b) -y[i]\n",
    "        print(err)\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + err*x[i,j]\n",
    "        dj_db = dj_db + err\n",
    "\n",
    "    return dj_dw/m, dj_db/m,var\n",
    "\n",
    "        \n",
    "\n",
    "# anand()\n",
    "\n",
    "def compute_cost(w,b,X_train,y):\n",
    "    counter = 0\n",
    "    for i in range(len(X_train)):\n",
    "        err = (np.dot(X_train[i],w)+b) -y[i]\n",
    "        counter = counter +err**2\n",
    "    return counter/(2*len(X_train))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "iteration = 1000\n",
    "alpha = 5.0e-7\n",
    "w = np.array([0,0,0,0])\n",
    "b = 0\n",
    "cost_funtion_list = []\n",
    "for  i in range(iteration):\n",
    "    \n",
    "    dj_dw, dj_db,var = compute_grdient(w,b,X_train,y_train)\n",
    "\n",
    "    cost_funtion_list.append(var)\n",
    "\n",
    "    w = w - alpha*dj_dw\n",
    "    b = b- alpha*dj_db\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(w)\n",
    "cost_funtion_list\n",
    "plt.plot(cost_funtion_list)\n",
    "plt.show()\n",
    "plt.plot(cost_funtion_list[100:])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "size,(ax1,ax2) = plt.subplots(1,2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def example_plot(ax):\n",
    "    ax.plot([1, 2])\n",
    "    ax.set_xlabel('x-label', fontsize=12)\n",
    "    ax.set_ylabel('y-label', fontsize=12)\n",
    "    ax.set_title('Title', fontsize=14)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, constrained_layout=True)\n",
    "print(axs.flat)\n",
    "# for i in range(leb)\n",
    "for ax in axs.flat:\n",
    "    print(ax)\n",
    "#     example_plot(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(100+np.arange(len(cost_funtion_list[100:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "delta = ['size(sqft)','bedrooms','floors','age',\"price\"]\n",
    "\n",
    "df = pd.read_csv(\"houses.txt\",names=['size(sqft)','bedrooms','floors','age',\"price\"])\n",
    "\n",
    "# df\n",
    "X_train = df.iloc[:,:4].to_numpy()\n",
    "y  = df.iloc[:,4].to_numpy()\n",
    "\n",
    "# print(X_train.to_numpy())\n",
    "# print(y.to_numpy())\n",
    "\n",
    "# def \n",
    "# check the data \n",
    "size,ax = plt.subplots(1,4,figsize=(10,3),sharey=True)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(df.iloc[:,i],y)\n",
    "    ax[i].set_xlabel(delta[i])\n",
    "ax[0].set_ylabel(delta[-1])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "delta = ['size(sqft)','bedrooms','floors','age',\"price\"]\n",
    "\n",
    "df = pd.read_csv(\"houses.txt\",names=['size(sqft)','bedrooms','floors','age',\"price\"])\n",
    "\n",
    "def comupte_grdient(w,b,x_train,y_train):\n",
    "    dw_dj = np.zeros(4)\n",
    "    m,n = x_train.shape\n",
    "    db_dj = 0\n",
    "    cost = compute_cost(w,b,x_train,y_train)\n",
    "    for i in range(m):\n",
    "        err = (np.dot(x_train[i],w) +b)-y_train[i]\n",
    "        for j in range(n):\n",
    "            \n",
    "            dw_dj[j] = dw_dj[j] + err*x_train[i,j]\n",
    "            # print(dw_dj)\n",
    "\n",
    "        db_dj+=err\n",
    "    return dw_dj/m,db_dj/m,cost\n",
    "\n",
    "    \n",
    "def compute_cost(w,b,x_train,y_train):\n",
    "        # dw_dj = np.zeros(4)\n",
    "    m,n = x_train.shape\n",
    "    # db_dj = 0\n",
    "    j_w_b = 0\n",
    "    for i in range(m):\n",
    "        j_w_b+=((np.dot(x_train[i],w) +b)-y_train[i])**2\n",
    "    return j_w_b/(2*m)\n",
    "    \n",
    "\n",
    "itertion = 10\n",
    "w = np.array([0,0,0,0,])\n",
    "b = 0\n",
    "alpha = 9.9e-7\n",
    "X_train = df.iloc[1:,:4].to_numpy()\n",
    "y  = df.iloc[1:,4].to_numpy()\n",
    "\n",
    "\n",
    "my_dic = {}\n",
    "my_dic[\"cost\"] = []\n",
    "my_dic[\"iteration\"] = []\n",
    "my_dic[\"parameters\"] = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(itertion):\n",
    "\n",
    "    dw_dj,db_dj,cost = comupte_grdient(w,b,X_train,y)\n",
    "    w = w-alpha*dw_dj\n",
    "    b = b-alpha*db_dj\n",
    "    \n",
    "\n",
    "    my_dic[\"cost\"].append(cost)\n",
    "    my_dic[\"iteration\"].append(i)\n",
    "    my_dic[\"parameters\"].append([w,b])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(my_dic[\"iteration\"])\n",
    "# for i in my_dic[\"parameters\"]:\n",
    "#     print(i)\n",
    "ws = np.array([i[0] for i in my_dic[\"parameters\"]])\n",
    "print(ws[:,0])\n",
    "\n",
    "rng = max(abs(ws[:,0].max()),abs(ws[:,0].min()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "size,ax = plt.subplots(1,2,figsize=(10,3))\n",
    "ax[0].plot(my_dic[\"iteration\"],my_dic[\"cost\"])\n",
    "ax[0].set_title(\"Iteration vs cost\")\n",
    "ax[0].set_ylabel(\"Cost\")\n",
    "ax[0].set_xlabel(\"Iteration\")\n",
    "ax[1].plot(ws[:,0],my_dic[\"cost\"])\n",
    "ax[1].set_title(\"w[0] vs cost\")\n",
    "ax[1].set_ylabel(\"Cost\")\n",
    "ax[1].set_xlabel(\"w[0]\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "l = [list(range(6)),list(range(6,12)),list(range(12,18)),list(range(18,24))]\n",
    "\n",
    "# print(l)\n",
    "l = [np.array(i) for i in l]\n",
    "l = np.array(l)\n",
    "print(l)\n",
    "\n",
    "hwllo = np.mean(l,axis=0)\n",
    "print(hwllo)\n",
    "\n",
    "\n",
    "hwllo = np.mean(l,axis=1)\n",
    "print(hwllo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 20, 1)\n",
    "y = 1 + x**2\n",
    "X = x.reshape(-1, 1)    \n",
    "\n",
    "print(y)\n",
    "m,n = X.shape\n",
    "\n",
    "def compute_grident(w,b,x,y):\n",
    "    dw_dj = np.zeros((n,))\n",
    "    dj_db = 0\n",
    "\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        err = np.dot(x[i],w)-y[i]\n",
    "        for j in range(n):\n",
    "            dw_dj[j] = dw_dj[j]+err*x[i,j]\n",
    "        dj_db = dj_db+err\n",
    "    \n",
    "    dw_dj = dw_dj/m\n",
    "    dj_db = dj_db/m\n",
    "\n",
    "    return dw_dj,dj_db\n",
    "\n",
    "\n",
    "w = np.zeros((n,))\n",
    "b = 0\n",
    "w_answer,d_answer = compute_grident(w,b,X,y)\n",
    "print(w_answer,d_answer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_matrix(X, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    " \n",
    "    Args:\n",
    "      X : (array_like Shape (m,n)) variable such as house size \n",
    "      y : (array_like Shape (m,1)) actual value \n",
    "      w : (array_like Shape (n,1)) Values of parameters of the model      \n",
    "      b : (scalar )                Values of parameter of the model      \n",
    "    Returns\n",
    "      dj_dw: (array_like Shape (n,1)) The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db: (scalar)                The gradient of the cost w.r.t. the parameter b. \n",
    "                                  \n",
    "    \"\"\"\n",
    "    m,n = X.shape\n",
    "    f_wb = X @ w + b              \n",
    "    e   = f_wb - y                \n",
    "    dj_dw  = (1/m) * (X.T @ e)    \n",
    "    dj_db  = (1/m) * np.sum(e)    \n",
    "        \n",
    "    return dj_db,dj_dw\n",
    "\n",
    "w = np.zeros((n,))\n",
    "b = 0\n",
    "w_answer,w_answer = compute_gradient_matrix(w,b,X,y)\n",
    "print(w_answer,w_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers  import Dense,Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError,BinaryCrossentropy\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "\n",
    "X_train = np.array([[1.0], [2.0]], dtype=np.float32)           #(size in 1000 square feet)\n",
    "Y_train = np.array([[300.0], [500.0]], dtype=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size,ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.scatter(X_train,Y_train,marker=\"x\",c=\"b\",label=\"data points\")\n",
    "ax.legend(fontsize=\"xx-large\")\n",
    "ax.set_ylabel(\"Price (in 1000s of dollars)\")\n",
    "ax.set_xlabel(\"size \")\n",
    "# ax.title(\"House_price (in 1000s of dollars) vs Size (in 1000s of sqfeet)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = tf.keras.layers.Dense(units=1,activation=\"linear\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1 = layer1(X)\n",
    "# print(X_train[0].reshape(1,1))\n",
    "a1 = layer1(X_train[0].reshape(1,1))\n",
    "print(a1)\n",
    "print(a1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer1.get_weights()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,MeanSquaredError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1.0], [2.0]], dtype=np.float32)           #(size in 1000 square feet)\n",
    "Y_train = np.array([[300.0], [500.0]], dtype=np.float32) \n",
    "\n",
    "\n",
    "size,ax = plt.subplots(1,1,figsize=(8,5))\n",
    "ax.scatter(X_train,Y_train,marker=\"x\",c=\"r\",label=\"data-points\")\n",
    "ax.legend(fontsize=\"xx-large\")\n",
    "# ax.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = tf.keras.layers.Dense(units=1,activation=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1.get_weights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train[0].reshape(1,1))\n",
    "a1 = layer1(X_train[0].reshape(1,1))\n",
    "print(a1.numpy())\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b=layer1.get_weights()\n",
    "print(w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "k = np.arange(6)\n",
    "print(k.reshape(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_w = np.array([[200]])\n",
    "set_b = np.array([100])\n",
    "layer1.set_weights([set_w,set_b])\n",
    "layer1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = layer1(X_train[0].reshape(1,1))\n",
    "a1in = np.dot(set_w,X_train[0].reshape(1,1)) + set_b\n",
    "a1in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train)\n",
    "import  matplotlib.pyplot as plt\n",
    "delta = layer1(X_train)\n",
    "delta1 = np.dot(X_train,set_w) + set_b\n",
    "# print(delta)\n",
    "# print(delta1)\n",
    "\n",
    "size,ax = plt.subplots(1,2,figsize=(20,6),sharey=True)\n",
    "for i in range(len(ax)):\n",
    "    # print(\"hello\")\n",
    "    ax[i].scatter(X_train,Y_train,marker=\"x\",c=\"r\")\n",
    "ax[0].plot(X_train,delta,label=\"tenserflow calucations\")\n",
    "ax[1].plot(X_train,delta1,label=\"numpy evalutions\")\n",
    "ax[0].legend(fontsize=\"xx-large\")\n",
    "ax[1].legend(fontsize=\"xx-large\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the The logistic regression on tenserflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"hello\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import  matplotlib.pyplot  as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([0., 1, 2, 3, 4, 5], dtype=np.float32) # 2-D Matrix\n",
    "Y_train = np.array([0,  0, 0, 1, 1, 1], dtype=np.float32)  # 2-D Matrix\n",
    "# print(X_train.reshape(-1,1))\n",
    "# print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = Y_train==1\n",
    "# pos = Y_train==0\n",
    "\n",
    "neg = Y_train==0\n",
    "size,ax = plt.subplots(1,figsize=(8,5))\n",
    "ax.scatter(X_train[pos],Y_train[pos],marker=\"x\",c=\"r\")\n",
    "ax.scatter(X_train[neg],Y_train[neg],marker=\"o\",c=\"b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([tf.keras.layers.Dense(1,input_dim =1,activation=\"sigmoid\",name=\"L1\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " L1 (Dense)                  (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7941171]] [0.]\n"
     ]
    }
   ],
   "source": [
    "logistic_layer = model.get_layer(\"L1\")\n",
    "# logistic_layer\n",
    "w,b = logistic_layer.get_weights()\n",
    "print(w,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[2.]], dtype=float32), array([-4.5], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "set_w = np.array([[2]])\n",
    "set_b = np.array([-4.5])\n",
    "logistic_layer.set_weights([set_w,set_b])\n",
    "print(logistic_layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " L1 (Dense)                  (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coffee_data():\n",
    "    \"\"\" Creates a coffee roasting data set.\n",
    "        roasting duration: 12-15 minutes is best\n",
    "        temperature range: 175-260C is best\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(2)\n",
    "    X = rng.random(400).reshape(-1,2)\n",
    "    X[:,1] = X[:,1] * 4 + 11.5          # 12-15 min is best\n",
    "    X[:,0] = X[:,0] * (285-150) + 150  # 350-500 F (175-260 C) is best\n",
    "    Y = np.zeros(len(X))\n",
    "    \n",
    "    i=0\n",
    "    for t,d in X:\n",
    "        y = -3/(260-175)*t + 21\n",
    "        if (t > 175 and t < 260 and d > 12 and d < 15 and d<=y ):\n",
    "            Y[i] = 1\n",
    "        else:\n",
    "            Y[i] = 0\n",
    "        i += 1\n",
    "\n",
    "    return (X,Y.reshape(-1,1))\n",
    "X,Y = load_coffee_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6597537\n"
     ]
    }
   ],
   "source": [
    "norm_l = tf.keras.layers.Normalization(axis=-1)\n",
    "norm_l.adapt(X)\n",
    "Xn  = norm_l(X)\n",
    "print(np.max(Xn[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(Xn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "Xt = np.tile(Xn,(1000,1))\n",
    "print(len(Xt[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xt = np.tile(Xn,(1000))\n",
    "# len(Xt[0])\n",
    "Yt = np.tile(Y,(1000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "model = Sequential([Input(shape=(2,)),\n",
    "Dense(3,activation='sigmoid',name = 'layer1'),\n",
    "Dense(1,activation='sigmoid',name = 'layer2'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 3)                 9         \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 params =  9 , L2 params =  4\n"
     ]
    }
   ],
   "source": [
    "L1_num_params = 2 * 3 + 3   # W1 parameters  + b1 parameters\n",
    "L2_num_params = 3 * 1 + 1   # W2 parameters  + b2 parameters\n",
    "print(\"L1 params = \", L1_num_params, \", L2 params = \", L2_num_params  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1(2, 3):\n",
      " [[ 1.0374069   0.2875024   0.6054542 ]\n",
      " [ 0.55408895 -0.10266924  0.42084217]] \n",
      "b1(3,): [0. 0. 0.]\n",
      "W2(3, 1):\n",
      " [[-1.0191844]\n",
      " [ 0.9591683]\n",
      " [-0.7720111]] \n",
      "b2(1,): [0.]\n"
     ]
    }
   ],
   "source": [
    "W1, b1 = model.get_layer(\"layer1\").get_weights()\n",
    "W2, b2 = model.get_layer(\"layer2\").get_weights()\n",
    "print(f\"W1{W1.shape}:\\n\", W1, f\"\\nb1{b1.shape}:\", b1)\n",
    "print(f\"W2{W2.shape}:\\n\", W2, f\"\\nb2{b2.shape}:\", b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6250/6250 [==============================] - 8s 1ms/step - loss: 7.2074e-06\n",
      "Epoch 2/10\n",
      "6250/6250 [==============================] - 7s 1ms/step - loss: 1.2591e-05\n",
      "Epoch 3/10\n",
      "6250/6250 [==============================] - 7s 1ms/step - loss: 4.9712e-06\n",
      "Epoch 4/10\n",
      "6250/6250 [==============================] - 7s 1ms/step - loss: 4.2249e-05\n",
      "Epoch 5/10\n",
      "6250/6250 [==============================] - 8s 1ms/step - loss: 1.3707e-05\n",
      "Epoch 6/10\n",
      "6250/6250 [==============================] - 7s 1ms/step - loss: 4.2881e-06\n",
      "Epoch 7/10\n",
      "6250/6250 [==============================] - 7s 1ms/step - loss: 1.1415e-05\n",
      "Epoch 8/10\n",
      "6250/6250 [==============================] - 7s 1ms/step - loss: 9.9794e-05\n",
      "Epoch 9/10\n",
      "6250/6250 [==============================] - 7s 1ms/step - loss: 5.7140e-06\n",
      "Epoch 10/10\n",
      "6250/6250 [==============================] - 7s 1ms/step - loss: 3.3368e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8be9780650>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    Xt,Yt,\n",
    "    epochs = 10,            \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.33198068 21.3858     18.910374  ]\n",
      " [-9.442187    0.40114433 15.809253  ]]\n",
      "[[-122.886215]\n",
      " [  99.00937 ]\n",
      " [-111.35261 ]]\n"
     ]
    }
   ],
   "source": [
    "W1_1,b1_1 = model.get_layer(\"layer1\").get_weights()\n",
    "print(W1)\n",
    "W2_1,b2_1 = model.get_layer(\"layer2\").get_weights()\n",
    "print(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.45160276 22.305038   19.359228  ]\n",
      " [-9.43275     0.40254402 16.107515  ]]\n",
      "[[-128.45157 ]\n",
      " [ 103.274734]\n",
      " [-117.79746 ]]\n"
     ]
    }
   ],
   "source": [
    "W1_10,b1_10 = model.get_layer(\"layer1\").get_weights()\n",
    "print(W1)\n",
    "W2_10,b2_10 = model.get_layer(\"layer2\").get_weights()\n",
    "print(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "predictions = \n",
      " [[9.9999911e-01]\n",
      " [7.8198274e-17]]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array([\n",
    "    [200,13.9],  # postive example\n",
    "    [200,17]])   # negative example\n",
    "X_testn = norm_l(X_test)\n",
    "predictions = model.predict(X_testn)\n",
    "print(\"predictions = \\n\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decisions = \n",
      "[[1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "yhat = np.zeros_like(predictions)\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >= 0.5:\n",
    "        yhat[i] = 1\n",
    "    else:\n",
    "        yhat[i] = 0\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94c9c2e95ec3d474548fdf5570e88189aea00269a8ad050d09413ba495a47d7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
