{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def compute_gradient(w,b,x_train,y_train):\n",
    "    for i in range(len(x_train)):\n",
    "        f_w = w*x_train[i] + b\n",
    "        new = f_w-y_train[i]\n",
    "        new = new*x_train[i]\n",
    "        f_b = w*x_train[i] + b\n",
    "        new1 = f_b-y_train[i]\n",
    "    return new/len(x_train), new1/len(x_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cost_fintion(w,b,x_train,y_train):\n",
    "    for i in range(len(x_train)):\n",
    "\n",
    "        f_wb = w*x_train[i] + b\n",
    "        f_wd = f_wb-y_train[i]\n",
    "        fw = f_wd**2\n",
    "    return fw/len(x_train)\n",
    "\n",
    "\n",
    "iteration = 10000\n",
    "x_train = np.array([1.0, 2.0])   #features\n",
    "y_train = np.array([300.0, 500.0]) \n",
    "alpha = 0.01\n",
    "w = 0\n",
    "b = 0\n",
    "\n",
    "for i in range(iteration):\n",
    "    f_w,f_b = compute_gradient(w,b,x_train,y_train)\n",
    "    print(cost_fintion(w,b,x_train,y_train))\n",
    "    w = w-alpha*f_w\n",
    "    b = b-alpha*f_b\n",
    "\n",
    "print(w*1+b)\n",
    "print(w*2+b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implemetation of linear regression multiveribale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def f_x(w,b,x):\n",
    "    delta_w = 0\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(x[i])):\n",
    "            delta_w += x[i][j]*w[j]\n",
    "    delta_w+=b\n",
    "    return  delta_w\n",
    "\n",
    "\n",
    "def compute_gredient(w,b,X_train,y_train,):\n",
    "    dj_dw = np.zeros((X_train.shape[1],))\n",
    "    dj_db= 0\n",
    "    \n",
    "    for i in range(len(X_train)):\n",
    "        delta = f_x(w,b,X_train)\n",
    "        delta = delta - y_train[i]\n",
    "        print(delta)\n",
    "\n",
    "        for j in range(len(X_train[1])):\n",
    "            dj_dw[j] = dj_dw[j] + delta*X_train[i,j]\n",
    "        dj_db = dj_db +delta\n",
    "    # print(dj_dw)\n",
    "    return dj_dw/len(X_train), dj_db/len(X_train)\n",
    "\n",
    "\n",
    "iterrations = 1000\n",
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n",
    "w = np.zeros((X_train.shape[1],))\n",
    "print(w)\n",
    "alpha = 0.001\n",
    "b = 0\n",
    "for i in range(iterrations):\n",
    "    # print(w)\n",
    "    dj_dw,dj_db = compute_gredient(w,b,X_train,y_train)\n",
    "    w = w-alpha*dj_dw\n",
    "    b = b- alpha*dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "new = ['size(sqft)','bedrooms','floors','age',\"price\"]\n",
    "df = pd.read_csv(\"houses.txt\",names=new)\n",
    "X_train = df.iloc[:,:4]\n",
    "y = df.iloc[:,4]\n",
    "# print(X_train)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size,ax = plt.subplots(1,4,figsize =(12,3),sharey=True)\n",
    "# print(size)\n",
    "# print(ax)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(X_train.iloc[:,i],y)\n",
    "    ax[i].set_xlabel(new[i])\n",
    "\n",
    "# ax[i+1].scatter(X_train.iloc[:,i+1],y)\n",
    "ax[0].set_ylabel(new[-1])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def compute_gradient(X, y, w, b): \n",
    "\n",
    "    m,n = X.shape           \n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw\n",
    "\n",
    "\n",
    "\n",
    "initial_w = np.array([0,0,0,0])\n",
    "initial_b = 0.\n",
    "num_iters = 1000\n",
    "alpha = 5.0e-7\n",
    "\n",
    "w = copy.deepcopy(initial_w)  \n",
    "b = initial_b\n",
    "X = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y = np.array([460, 232, 178])\n",
    "for i in range(num_iters):\n",
    "\n",
    "    dj_db,dj_dw = compute_gradient(X, y, w, b)   \n",
    "\n",
    "    w = w - alpha * dj_dw               \n",
    "    b = b - alpha * dj_db               \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def compute_gradient(X, y, w, b): \n",
    "\n",
    "    m,n = X.shape           \n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "\n",
    "    for i in range(m):                             \n",
    "        err = (np.dot(X[i], w) + b) - y[i]   \n",
    "        for j in range(n):                         \n",
    "            dj_dw[j] = dj_dw[j] + err * X[i, j]    \n",
    "        dj_db = dj_db + err                        \n",
    "    dj_dw = dj_dw / m                                \n",
    "    dj_db = dj_db / m                                \n",
    "        \n",
    "    return dj_db, dj_dw\n",
    "\n",
    "\n",
    "initial_w = np.array([0,0,0,0])\n",
    "initial_b = 0.\n",
    "num_iters = 1000\n",
    "alpha = 5.0e-7\n",
    "\n",
    "\n",
    "# loading the data part \n",
    "new = ['size(sqft)','bedrooms','floors','age',\"price\"]\n",
    "df = pd.read_csv(\"houses.txt\",names=new)\n",
    "X_train = df.iloc[:,:4]\n",
    "y = df.iloc[:,4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax = plt.subplots(1,4,figsize=(10,3),sharey=True)\n",
    "# plt.show()\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(df.iloc[:,i],y)\n",
    "    ax[i].set_xlabel(new[i])\n",
    "# ax[0].scatter(df.iloc[:,-1])\n",
    "ax[0].set_ylabel(str(new[-1])+ \"in (1000's)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax=plt.subplots(1, 4, figsize=(12, 3), sharey=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = df.iloc[:,:4]\n",
    "# print(X_train)\n",
    "l = []\n",
    "for i in range(len(X_train)):\n",
    "    l.append(X_train.iloc[i,:].values)\n",
    "\n",
    "new_X_train = np.array(l)\n",
    "new_y_train = y.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_X_train\n",
    "# new_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])\n",
    "\n",
    "\n",
    "m,n = X_train.shape\n",
    "print(m,n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grdient(w,b,x,y):\n",
    "    var = compute_cost(w,b,x,y)\n",
    "    dj_dw = np.array([0,0,0,0])\n",
    "    dj_db = 0\n",
    "    for i in range(m):\n",
    "        err = (np.dot(x[i],w)+b) -y[i]\n",
    "        print(err)\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + err*x[i,j]\n",
    "        dj_db = dj_db + err\n",
    "\n",
    "    return dj_dw/m, dj_db/m,var\n",
    "\n",
    "        \n",
    "\n",
    "# anand()\n",
    "\n",
    "def compute_cost(w,b,X_train,y):\n",
    "    counter = 0\n",
    "    for i in range(len(X_train)):\n",
    "        err = (np.dot(X_train[i],w)+b) -y[i]\n",
    "        counter = counter +err**2\n",
    "    return counter/(2*len(X_train))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "iteration = 1000\n",
    "alpha = 5.0e-7\n",
    "w = np.array([0,0,0,0])\n",
    "b = 0\n",
    "cost_funtion_list = []\n",
    "for  i in range(iteration):\n",
    "    \n",
    "    dj_dw, dj_db,var = compute_grdient(w,b,X_train,y_train)\n",
    "\n",
    "    cost_funtion_list.append(var)\n",
    "\n",
    "    w = w - alpha*dj_dw\n",
    "    b = b- alpha*dj_db\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(w)\n",
    "cost_funtion_list\n",
    "plt.plot(cost_funtion_list)\n",
    "plt.show()\n",
    "plt.plot(cost_funtion_list[100:])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "size,(ax1,ax2) = plt.subplots(1,2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def example_plot(ax):\n",
    "    ax.plot([1, 2])\n",
    "    ax.set_xlabel('x-label', fontsize=12)\n",
    "    ax.set_ylabel('y-label', fontsize=12)\n",
    "    ax.set_title('Title', fontsize=14)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, constrained_layout=True)\n",
    "print(axs.flat)\n",
    "# for i in range(leb)\n",
    "for ax in axs.flat:\n",
    "    print(ax)\n",
    "#     example_plot(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(100+np.arange(len(cost_funtion_list[100:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "delta = ['size(sqft)','bedrooms','floors','age',\"price\"]\n",
    "\n",
    "df = pd.read_csv(\"houses.txt\",names=['size(sqft)','bedrooms','floors','age',\"price\"])\n",
    "\n",
    "# df\n",
    "X_train = df.iloc[:,:4].to_numpy()\n",
    "y  = df.iloc[:,4].to_numpy()\n",
    "\n",
    "# print(X_train.to_numpy())\n",
    "# print(y.to_numpy())\n",
    "\n",
    "# def \n",
    "# check the data \n",
    "size,ax = plt.subplots(1,4,figsize=(10,3),sharey=True)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(df.iloc[:,i],y)\n",
    "    ax[i].set_xlabel(delta[i])\n",
    "ax[0].set_ylabel(delta[-1])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "delta = ['size(sqft)','bedrooms','floors','age',\"price\"]\n",
    "\n",
    "df = pd.read_csv(\"houses.txt\",names=['size(sqft)','bedrooms','floors','age',\"price\"])\n",
    "\n",
    "def comupte_grdient(w,b,x_train,y_train):\n",
    "    dw_dj = np.zeros(4)\n",
    "    m,n = x_train.shape\n",
    "    db_dj = 0\n",
    "    cost = compute_cost(w,b,x_train,y_train)\n",
    "    for i in range(m):\n",
    "        err = (np.dot(x_train[i],w) +b)-y_train[i]\n",
    "        for j in range(n):\n",
    "            \n",
    "            dw_dj[j] = dw_dj[j] + err*x_train[i,j]\n",
    "            # print(dw_dj)\n",
    "\n",
    "        db_dj+=err\n",
    "    return dw_dj/m,db_dj/m,cost\n",
    "\n",
    "    \n",
    "def compute_cost(w,b,x_train,y_train):\n",
    "        # dw_dj = np.zeros(4)\n",
    "    m,n = x_train.shape\n",
    "    # db_dj = 0\n",
    "    j_w_b = 0\n",
    "    for i in range(m):\n",
    "        j_w_b+=((np.dot(x_train[i],w) +b)-y_train[i])**2\n",
    "    return j_w_b/(2*m)\n",
    "    \n",
    "\n",
    "itertion = 10\n",
    "w = np.array([0,0,0,0,])\n",
    "b = 0\n",
    "alpha = 9.9e-7\n",
    "X_train = df.iloc[1:,:4].to_numpy()\n",
    "y  = df.iloc[1:,4].to_numpy()\n",
    "\n",
    "\n",
    "my_dic = {}\n",
    "my_dic[\"cost\"] = []\n",
    "my_dic[\"iteration\"] = []\n",
    "my_dic[\"parameters\"] = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(itertion):\n",
    "\n",
    "    dw_dj,db_dj,cost = comupte_grdient(w,b,X_train,y)\n",
    "    w = w-alpha*dw_dj\n",
    "    b = b-alpha*db_dj\n",
    "    \n",
    "\n",
    "    my_dic[\"cost\"].append(cost)\n",
    "    my_dic[\"iteration\"].append(i)\n",
    "    my_dic[\"parameters\"].append([w,b])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(my_dic[\"iteration\"])\n",
    "# for i in my_dic[\"parameters\"]:\n",
    "#     print(i)\n",
    "ws = np.array([i[0] for i in my_dic[\"parameters\"]])\n",
    "print(ws[:,0])\n",
    "\n",
    "rng = max(abs(ws[:,0].max()),abs(ws[:,0].min()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "size,ax = plt.subplots(1,2,figsize=(10,3))\n",
    "ax[0].plot(my_dic[\"iteration\"],my_dic[\"cost\"])\n",
    "ax[0].set_title(\"Iteration vs cost\")\n",
    "ax[0].set_ylabel(\"Cost\")\n",
    "ax[0].set_xlabel(\"Iteration\")\n",
    "ax[1].plot(ws[:,0],my_dic[\"cost\"])\n",
    "ax[1].set_title(\"w[0] vs cost\")\n",
    "ax[1].set_ylabel(\"Cost\")\n",
    "ax[1].set_xlabel(\"w[0]\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "l = [list(range(6)),list(range(6,12)),list(range(12,18)),list(range(18,24))]\n",
    "\n",
    "# print(l)\n",
    "l = [np.array(i) for i in l]\n",
    "l = np.array(l)\n",
    "print(l)\n",
    "\n",
    "hwllo = np.mean(l,axis=0)\n",
    "print(hwllo)\n",
    "\n",
    "\n",
    "hwllo = np.mean(l,axis=1)\n",
    "print(hwllo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 20, 1)\n",
    "y = 1 + x**2\n",
    "X = x.reshape(-1, 1)    \n",
    "\n",
    "print(y)\n",
    "m,n = X.shape\n",
    "\n",
    "def compute_grident(w,b,x,y):\n",
    "    dw_dj = np.zeros((n,))\n",
    "    dj_db = 0\n",
    "\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        err = np.dot(x[i],w)-y[i]\n",
    "        for j in range(n):\n",
    "            dw_dj[j] = dw_dj[j]+err*x[i,j]\n",
    "        dj_db = dj_db+err\n",
    "    \n",
    "    dw_dj = dw_dj/m\n",
    "    dj_db = dj_db/m\n",
    "\n",
    "    return dw_dj,dj_db\n",
    "\n",
    "\n",
    "w = np.zeros((n,))\n",
    "b = 0\n",
    "w_answer,d_answer = compute_grident(w,b,X,y)\n",
    "print(w_answer,d_answer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_matrix(X, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    " \n",
    "    Args:\n",
    "      X : (array_like Shape (m,n)) variable such as house size \n",
    "      y : (array_like Shape (m,1)) actual value \n",
    "      w : (array_like Shape (n,1)) Values of parameters of the model      \n",
    "      b : (scalar )                Values of parameter of the model      \n",
    "    Returns\n",
    "      dj_dw: (array_like Shape (n,1)) The gradient of the cost w.r.t. the parameters w. \n",
    "      dj_db: (scalar)                The gradient of the cost w.r.t. the parameter b. \n",
    "                                  \n",
    "    \"\"\"\n",
    "    m,n = X.shape\n",
    "    f_wb = X @ w + b              \n",
    "    e   = f_wb - y                \n",
    "    dj_dw  = (1/m) * (X.T @ e)    \n",
    "    dj_db  = (1/m) * np.sum(e)    \n",
    "        \n",
    "    return dj_db,dj_dw\n",
    "\n",
    "w = np.zeros((n,))\n",
    "b = 0\n",
    "w_answer,w_answer = compute_gradient_matrix(w,b,X,y)\n",
    "print(w_answer,w_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers  import Dense,Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError,BinaryCrossentropy\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "\n",
    "X_train = np.array([[1.0], [2.0]], dtype=np.float32)           #(size in 1000 square feet)\n",
    "Y_train = np.array([[300.0], [500.0]], dtype=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size,ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.scatter(X_train,Y_train,marker=\"x\",c=\"b\",label=\"data points\")\n",
    "ax.legend(fontsize=\"xx-large\")\n",
    "ax.set_ylabel(\"Price (in 1000s of dollars)\")\n",
    "ax.set_xlabel(\"size \")\n",
    "# ax.title(\"House_price (in 1000s of dollars) vs Size (in 1000s of sqfeet)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = tf.keras.layers.Dense(units=1,activation=\"linear\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1 = layer1(X)\n",
    "# print(X_train[0].reshape(1,1))\n",
    "a1 = layer1(X_train[0].reshape(1,1))\n",
    "print(a1)\n",
    "print(a1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer1.get_weights()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,MeanSquaredError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1.0], [2.0]], dtype=np.float32)           #(size in 1000 square feet)\n",
    "Y_train = np.array([[300.0], [500.0]], dtype=np.float32) \n",
    "\n",
    "\n",
    "size,ax = plt.subplots(1,1,figsize=(8,5))\n",
    "ax.scatter(X_train,Y_train,marker=\"x\",c=\"r\",label=\"data-points\")\n",
    "ax.legend(fontsize=\"xx-large\")\n",
    "# ax.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = tf.keras.layers.Dense(units=1,activation=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1.get_weights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train[0].reshape(1,1))\n",
    "a1 = layer1(X_train[0].reshape(1,1))\n",
    "print(a1.numpy())\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b=layer1.get_weights()\n",
    "print(w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "k = np.arange(6)\n",
    "print(k.reshape(3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_w = np.array([[200]])\n",
    "set_b = np.array([100])\n",
    "layer1.set_weights([set_w,set_b])\n",
    "layer1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = layer1(X_train[0].reshape(1,1))\n",
    "a1in = np.dot(set_w,X_train[0].reshape(1,1)) + set_b\n",
    "a1in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train)\n",
    "import  matplotlib.pyplot as plt\n",
    "delta = layer1(X_train)\n",
    "delta1 = np.dot(X_train,set_w) + set_b\n",
    "# print(delta)\n",
    "# print(delta1)\n",
    "\n",
    "size,ax = plt.subplots(1,2,figsize=(20,6),sharey=True)\n",
    "for i in range(len(ax)):\n",
    "    # print(\"hello\")\n",
    "    ax[i].scatter(X_train,Y_train,marker=\"x\",c=\"r\")\n",
    "ax[0].plot(X_train,delta,label=\"tenserflow calucations\")\n",
    "ax[1].plot(X_train,delta1,label=\"numpy evalutions\")\n",
    "ax[0].legend(fontsize=\"xx-large\")\n",
    "ax[1].legend(fontsize=\"xx-large\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the The logistic regression on tenserflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"hello\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import  matplotlib.pyplot  as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([0., 1, 2, 3, 4, 5], dtype=np.float32) # 2-D Matrix\n",
    "Y_train = np.array([0,  0, 0, 1, 1, 1], dtype=np.float32)  # 2-D Matrix\n",
    "# print(X_train.reshape(-1,1))\n",
    "# print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = Y_train==1\n",
    "# pos = Y_train==0\n",
    "\n",
    "neg = Y_train==0\n",
    "size,ax = plt.subplots(1,figsize=(8,5))\n",
    "ax.scatter(X_train[pos],Y_train[pos],marker=\"x\",c=\"r\")\n",
    "ax.scatter(X_train[neg],Y_train[neg],marker=\"o\",c=\"b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy,MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([tf.keras.layers.Dense(1,input_dim =1,activation=\"sigmoid\",name=\"L1\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_layer = model.get_layer(\"L1\")\n",
    "# logistic_layer\n",
    "w,b = logistic_layer.get_weights()\n",
    "print(w,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_w = np.array([[2]])\n",
    "set_b = np.array([-4.5])\n",
    "logistic_layer.set_weights([set_w,set_b])\n",
    "print(logistic_layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coffee_data():\n",
    "    \"\"\" Creates a coffee roasting data set.\n",
    "        roasting duration: 12-15 minutes is best\n",
    "        temperature range: 175-260C is best\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(2)\n",
    "    X = rng.random(400).reshape(-1,2)\n",
    "    X[:,1] = X[:,1] * 4 + 11.5          # 12-15 min is best\n",
    "    X[:,0] = X[:,0] * (285-150) + 150  # 350-500 F (175-260 C) is best\n",
    "    Y = np.zeros(len(X))\n",
    "    \n",
    "    i=0\n",
    "    for t,d in X:\n",
    "        y = -3/(260-175)*t + 21\n",
    "        if (t > 175 and t < 260 and d > 12 and d < 15 and d<=y ):\n",
    "            Y[i] = 1\n",
    "        else:\n",
    "            Y[i] = 0\n",
    "        i += 1\n",
    "\n",
    "    return (X,Y.reshape(-1,1))\n",
    "X,Y = load_coffee_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_l = tf.keras.layers.Normalization(axis=-1)\n",
    "norm_l.adapt(X)\n",
    "Xn  = norm_l(X)\n",
    "print(np.max(Xn[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Xn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = np.tile(Xn,(1000,1))\n",
    "print(len(Xt[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xt = np.tile(Xn,(1000))\n",
    "# len(Xt[0])\n",
    "Yt = np.tile(Y,(1000,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "model = Sequential([Input(shape=(2,)),\n",
    "Dense(3,activation='sigmoid',name = 'layer1'),\n",
    "Dense(1,activation='sigmoid',name = 'layer2'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_num_params = 2 * 3 + 3   # W1 parameters  + b1 parameters\n",
    "L2_num_params = 3 * 1 + 1   # W2 parameters  + b2 parameters\n",
    "print(\"L1 params = \", L1_num_params, \", L2 params = \", L2_num_params  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1 = model.get_layer(\"layer1\").get_weights()\n",
    "W2, b2 = model.get_layer(\"layer2\").get_weights()\n",
    "print(f\"W1{W1.shape}:\\n\", W1, f\"\\nb1{b1.shape}:\", b1)\n",
    "print(f\"W2{W2.shape}:\\n\", W2, f\"\\nb2{b2.shape}:\", b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    Xt,Yt,\n",
    "    epochs = 10,            \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_1,b1_1 = model.get_layer(\"layer1\").get_weights()\n",
    "print(W1)\n",
    "W2_1,b2_1 = model.get_layer(\"layer2\").get_weights()\n",
    "print(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_10,b1_10 = model.get_layer(\"layer1\").get_weights()\n",
    "print(W1)\n",
    "W2_10,b2_10 = model.get_layer(\"layer2\").get_weights()\n",
    "print(W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([\n",
    "    [200,13.9],  # postive example\n",
    "    [200,17]])   # negative example\n",
    "X_testn = norm_l(X_test)\n",
    "predictions = model.predict(X_testn)\n",
    "print(\"predictions = \\n\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.zeros_like(predictions)\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >= 0.5:\n",
    "        yhat[i] = 1\n",
    "    else:\n",
    "        yhat[i] = 0\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1.0], [2.0]], dtype=np.float32)           #(size in 1000 square feet)\n",
    "Y_train = np.array([[300.0], [500.0]], dtype=np.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size,ax = plt.subplots(1,2,figsize =(10,4))\n",
    "ax[0].scatter(X_train,Y_train,marker=\"x\",color=\"red\",label=\"readings\")\n",
    "ax[0].legend(loc=\"upper left\",fontsize =\"xx-large\",)\n",
    "ax[0].set_xlabel(\"size in sq.ft\")\n",
    "ax[0].set_ylabel(\"size in sq.ft\")\n",
    "\n",
    "\n",
    "\n",
    "ax[1].scatter(X_train,Y_train,marker=\"x\",color=\"red\",label=\"readings\")\n",
    "ax[1].legend(loc=\"upper left\",fontsize =\"xx-large\",)\n",
    "ax[1].set_xlabel(\"size in sq.ft\")\n",
    "ax[1].set_ylabel(\"size in sq.ft\")\n",
    "ax[1].plot(X_train,Y_train,c=\"b\",label=\"readings\")\n",
    "ax[1].legend(loc=\"upper left\",fontsize =\"xx-large\",)\n",
    "ax[1].set_xlabel(\"size in sq.ft\")\n",
    "ax[1].set_ylabel(\"size in sq.ft\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing  the neral network in tenserflow\n",
    "linear_layer = tf.keras.layers.Dense(units=1,activation=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer.get_weights()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[0].reshape(1,1))\n",
    "\n",
    "a1 = linear_layer(X_train[0].reshape(1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_w = np.array([[200]])\n",
    "set_b = np.array([100])\n",
    "linear_layer.set_weights([set_w, set_b])\n",
    "print(linear_layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 =linear_layer(X_train[0].reshape(1,1))\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prideiction_tf = linear_layer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prideiction_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coffee_data():\n",
    "    \"\"\" Creates a coffee roasting data set.\n",
    "        roasting duration: 12-15 minutes is best\n",
    "        temperature range: 175-260C is best\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(2)\n",
    "    X = rng.random(400).reshape(-1,2)\n",
    "    X[:,1] = X[:,1] * 4 + 11.5          # 12-15 min is best\n",
    "    X[:,0] = X[:,0] * (285-150) + 150  # 350-500 F (175-260 C) is best\n",
    "    Y = np.zeros(len(X))\n",
    "    \n",
    "    i=0\n",
    "    for t,d in X:\n",
    "        y = -3/(260-175)*t + 21\n",
    "        if (t > 175 and t < 260 and d > 12 and d < 15 and d<=y ):\n",
    "            Y[i] = 1\n",
    "        else:\n",
    "            Y[i] = 0\n",
    "        i += 1\n",
    "\n",
    "    return (X, Y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = load_coffee_data()\n",
    "print(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X)\n",
    "# print(Y)\n",
    "pos = Y.reshape(-1,1)== 1\n",
    "neg = Y.reshape(-1,1)== 0\n",
    "\n",
    "\n",
    "\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[pos.reshape(-1)][:,0])\n",
    "\n",
    "size,ax = plt.subplots(1,2,figsize=(8,5))\n",
    "ax[0].scatter(X[pos.reshape(-1)][:,0],X[pos.reshape(-1)][:,1],c='r',marker=\"x\")\n",
    "ax[1].scatter(X[neg.reshape(-1)][:,0],X[pos.reshape(-1)][:,1],c='r',marker=\"x\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr= [1,2,3,4,5]\n",
    "# print(arr)\n",
    "\n",
    "def iterrator(l):\n",
    "    if len(l)==1:\n",
    "        return str(l[0])\n",
    "    else:\n",
    "        print(l[1:],\"--------------------------------\")\n",
    "        return str(l[0])+\" \"+iterrator(l[1:])\n",
    "iterrator(arr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Solution:    \n",
    "    #Complete this function\n",
    "    def printNos(self,N):\n",
    "        if N!=1:\n",
    "            self.printNos(N-1)\n",
    "        print(N,end=\" \")            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    T = 1\n",
    "    while T>0:\n",
    "        N = 10\n",
    "        ob = Solution()\n",
    "\n",
    "        ob.printNos(N)\n",
    "        print()\n",
    "        T-=1\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coffee_data():\n",
    "    \"\"\" Creates a coffee roasting data set.\n",
    "        roasting duration: 12-15 minutes is best\n",
    "        temperature range: 175-260C is best\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(2)\n",
    "    X = rng.random(400).reshape(-1,2)\n",
    "    X[:,1] = X[:,1] * 4 + 11.5          # 12-15 min is best\n",
    "    X[:,0] = X[:,0] * (285-150) + 150  # 350-500 F (175-260 C) is best\n",
    "    Y = np.zeros(len(X))\n",
    "    \n",
    "    i=0\n",
    "    for t,d in X:\n",
    "        y = -3/(260-175)*t + 21\n",
    "        if (t > 175 and t < 260 and d > 12 and d < 15 and d<=y ):\n",
    "            Y[i] = 1\n",
    "        else:\n",
    "            Y[i] = 0\n",
    "        i += 1\n",
    "\n",
    "    return (X, Y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = load_coffee_data();\n",
    "norm_l = tf.keras.layers.Normalization(axis=-1)\n",
    "norm_l.adapt(X)  # learns mean, variance\n",
    "Xn = norm_l(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y)\n",
    "Xt = np.tile(Xn,(1000,1))\n",
    "Yt= np.tile(Y,(1000,1))   \n",
    "print(Xt.shape, Yt.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Xt)\n",
    "# for i in Xt:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(2,)),\n",
    "        Dense(3, activation='sigmoid', name = 'layer1'),\n",
    "        Dense(1, activation='sigmoid', name = 'layer2')\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    Xt,Yt,            \n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([\n",
    "    [200,13.9],  # postive example\n",
    "    [200,17]])   # negative example\n",
    "X_testn = norm_l(X_test)\n",
    "predictions = model.predict(X_testn)\n",
    "print(\"predictions = \\n\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.zeros_like(predictions)\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >= 0.5:\n",
    "        yhat[i] = 1\n",
    "    else:\n",
    "        yhat[i] = 0\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coffee_data():\n",
    "    \"\"\" Creates a coffee roasting data set.\n",
    "        roasting duration: 12-15 minutes is best\n",
    "        temperature range: 175-260C is best\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(2)\n",
    "    X = rng.random(400).reshape(-1,2)\n",
    "    X[:,1] = X[:,1] * 4 + 11.5          # 12-15 min is best\n",
    "    X[:,0] = X[:,0] * (285-150) + 150  # 350-500 F (175-260 C) is best\n",
    "    Y = np.zeros(len(X))\n",
    "    \n",
    "    i=0\n",
    "    for t,d in X:\n",
    "        y = -3/(260-175)*t + 21\n",
    "        if (t > 175 and t < 260 and d > 12 and d < 15 and d<=y ):\n",
    "            Y[i] = 1\n",
    "        else:\n",
    "            Y[i] = 0\n",
    "        i += 1\n",
    "\n",
    "    return (X, Y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X)\n",
    "# print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z : array_like\n",
    "        A scalar or numpy array of any size.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "     g : array_like\n",
    "         sigmoid(z)\n",
    "    \"\"\"\n",
    "    z = np.clip( z, -500, 500 ) \n",
    "    print(z)          \n",
    "    g = 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.574442516811659"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_tmp = np.array( [[-8.93,  0.29, 12.9 ], [-0.1,  -7.32, 10.81]] )\n",
    "b1_tmp = np.array( [-9.82, -9.28,  0.96] )\n",
    "W2_tmp = np.array( [[-31.18], [-27.59], [-32.56]] )\n",
    "b2_tmp = np.array( [15.41] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst = np.array([\n",
    "    [200,13.9],  # postive example\n",
    "    [200,17]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94c9c2e95ec3d474548fdf5570e88189aea00269a8ad050d09413ba495a47d7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
